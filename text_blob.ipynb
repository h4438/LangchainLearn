{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d2b5d1-c1a2-48e2-97b3-2506999d649a",
   "metadata": {},
   "source": [
    "# Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b47c07-ab5e-4697-a835-f40e589a6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "userText = \"Shut up! You are an idiot\"\n",
    "tb = TextBlob(userText)\n",
    "# dir(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac13793f-d4f8-4543-abfc-5c49f5ae9516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8\n"
     ]
    }
   ],
   "source": [
    "subjectivity = tb.subjectivity\n",
    "polarity = round(tb.polarity, 2)\n",
    "print(polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1113c5-ab88-4371-9ce7-77fd6a8e3d43",
   "metadata": {},
   "source": [
    "# 1 try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d86d7234-3a13-49b5-8140-ac909398d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI ready\n",
      "Enable tracing at text_blob\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from setup import get_openai_model, enable_tracing\n",
    "\n",
    "MODEL = get_openai_model()\n",
    "enable_tracing(\"text_blob\")\n",
    "\n",
    "\n",
    "# define the output\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"sentiment\", description=\"a sentiment label based on the user text. It should be either Negative, Positive or Neutral\"),\n",
    "    ResponseSchema(name=\"reason\", description=\"the reason behind your answer\"),\n",
    "    ResponseSchema(name=\"reply\", description=\"the best reply to the given user text\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# prompt template\n",
    "template = \"\"\"You are good at detecting human emotion. All emotions you know are Negative, Positive and Neutral.\n",
    "Given a human text, subjectivity and polarity, your job is to answer as best as possible.\n",
    "Know that subjectivity is a measure of how much of a text is based on personal opinions or beliefs, rather than on facts. \n",
    "It is a float value between 0 and 1, where 0 represents an objective text and 1 represents a highly subjective text.\n",
    "Also know that polarity is a indicator for the sentiment of the given user text, negative value means Negative, positive value means Positive and 0 means Neutral.\n",
    "{format_instructions}\n",
    "User text: {text}\n",
    "Subjectivity: {subjectivity}\n",
    "Polarity: {polarity}\"\"\"\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\",\"subjectivity\",\"polarity\"],\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "# Build chain\n",
    "sentiment_chain = LLMChain(llm=MODEL, prompt=prompt, output_key='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efad7591-eb0f-4867-b487-55e32050ccc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Shut up! You are an idiot',\n",
       " 'polarity': -0.8,\n",
       " 'subjectivity': 0.8,\n",
       " 'result': '\\n\\n```json\\n{\\n\\t\"sentiment\": \"Negative\",\\n\\t\"reason\": \"The user text contains negative words and has a negative polarity.\",\\n\\t\"reply\": \"I understand that you are frustrated, but please refrain from using such language.\"\\n}\\n```'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = sentiment_chain({\"text\": userText, \"polarity\": polarity, \"subjectivity\": subjectivity})\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2a14f-f3a7-4dcb-8607-c9de776a99cf",
   "metadata": {},
   "source": [
    "# 2 try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017734a-42bc-4150-bb55-c2152fa9a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from setup import get_openai_model, enable_tracing\n",
    "\n",
    "MODEL = get_openai_model()\n",
    "enable_tracing(\"text_blob\")\n",
    "\n",
    "emotions = ['Happy ðŸ˜Š','Sad ðŸ˜”','Angry ðŸ˜ ','Surprise ðŸ˜²','Fear ðŸ˜¨']\n",
    "\n",
    "\n",
    "for emo in emotions:\n",
    "    emos = emo.split(\" \")\n",
    "    des = f\"\"\"a js object contains two properties.\n",
    "    The first one is label: str // always return '{emos[1]}' \"\"\"\n",
    "    schema = ResponseSchema(name=emos[0], description=des)\n",
    "    \n",
    "# define the output\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"sentiment\", description=\"a sentiment label based on the user text. It should be either Negative, Positive or Neutral\"),\n",
    "    ResponseSchema(name=\"reason\", description=\"the reason behind your answer\"),\n",
    "    ResponseSchema(name=\"reply\", description=\"the best reply to the given user text\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# prompt template\n",
    "template = \"\"\"You are good at detecting human emotion. All emotions you know are Negative, Positive and Neutral.\n",
    "Given a human text, subjectivity and polarity, your job is to answer as best as possible.\n",
    "Know that subjectivity is a measure of how much of a text is based on personal opinions or beliefs, rather than on facts. \n",
    "It is a float value between 0 and 1, where 0 represents an objective text and 1 represents a highly subjective text.\n",
    "Also know that polarity is a indicator for the sentiment of the given user text, negative value means Negative, positive value means Positive and 0 means Neutral.\n",
    "{format_instructions}\n",
    "User text: {text}\n",
    "Subjectivity: {subjectivity}\n",
    "Polarity: {polarity}\"\"\"\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\",\"subjectivity\",\"polarity\"],\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "# Build chain\n",
    "sentiment_chain = LLMChain(llm=MODEL, prompt=prompt, output_key='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45b5fa-484b-4560-bddc-c4d2c0199dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
