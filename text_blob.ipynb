{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d2b5d1-c1a2-48e2-97b3-2506999d649a",
   "metadata": {},
   "source": [
    "# Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b47c07-ab5e-4697-a835-f40e589a6dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac13793f-d4f8-4543-abfc-5c49f5ae9516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "userText = \"Shut up! You are an idiot\"\n",
    "tb = TextBlob(userText)\n",
    "subjectivity = tb.subjectivity\n",
    "polarity = round(tb.polarity, 2)\n",
    "print(polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1113c5-ab88-4371-9ce7-77fd6a8e3d43",
   "metadata": {},
   "source": [
    "# 1 try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86d7234-3a13-49b5-8140-ac909398d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI ready\n",
      "Enable tracing at text_blob\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from setup import get_openai_model, enable_tracing\n",
    "\n",
    "MODEL = get_openai_model()\n",
    "enable_tracing(\"text_blob\")\n",
    "\n",
    "\n",
    "# define the output\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"sentiment\", description=\"a sentiment label based on the user text. It should be either Negative, Positive or Neutral\"),\n",
    "    ResponseSchema(name=\"reason\", description=\"\"\"\n",
    "    If the sentiment is Negative then return the reason why the user shouldn't have said that.\n",
    "    If the sentiment is Positive then return a compliment.\n",
    "    For Neutral then return a instruct for a better message. \n",
    "    \"\"\"),\n",
    "    ResponseSchema(name=\"reply\", description=\"the best and friendliest replacement to the given user text\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# prompt template\n",
    "template = \"\"\"You are good at detecting human emotion. All emotions you know are Negative, Positive and Neutral.\n",
    "Given a human text, subjectivity and polarity, your job is to answer as best as possible.\n",
    "Know that subjectivity is a measure of how much of a text is based on personal opinions or beliefs, rather than on facts. \n",
    "It is a float value between 0 and 1, where 0 represents an objective text and 1 represents a highly subjective text.\n",
    "Also know that polarity is a indicator for the sentiment of the given user text, negative value means Negative, positive value means Positive and 0 means Neutral.\n",
    "{format_instructions}\n",
    "User text: {text}\n",
    "Subjectivity: {subjectivity}\n",
    "Polarity: {polarity}\"\"\"\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\",\"subjectivity\",\"polarity\"],\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "# Build chain\n",
    "sentiment_chain = LLMChain(llm=MODEL, prompt=prompt, output_key='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efad7591-eb0f-4867-b487-55e32050ccc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Have you heard about the new school',\n",
       " 'polarity': 0.14,\n",
       " 'subjectivity': 0.45454545454545453,\n",
       " 'result': '285714285714285\\n\\n```json\\n{\\n\\t\"sentiment\": \"Neutral\",\\n\\t\"reason\": \"This statement is too vague and does not provide enough information.\",\\n\\t\"reply\": \"What do you know about the new school?\"\\n}\\n```'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "userText = \"Have you heard about the new school\"\n",
    "tb = TextBlob(userText)\n",
    "subjectivity = tb.subjectivity\n",
    "polarity = round(tb.polarity, 2)\n",
    "\n",
    "ans = sentiment_chain({\"text\": userText, \"polarity\": polarity, \"subjectivity\": subjectivity})\n",
    "# ans = sentiment_chain.predict_and_parse(text=userText, polarity=polarity, subjectivity=subjectivity)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f140fc8-79fc-41ce-8089-308852d59b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'Neutral',\n",
       " 'reason': 'This statement is too vague and does not provide enough information.',\n",
       " 'reply': 'What do you know about the new school?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = output_parser.parse(ans['result'])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2a14f-f3a7-4dcb-8607-c9de776a99cf",
   "metadata": {},
   "source": [
    "# 2 try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a017734a-42bc-4150-bb55-c2152fa9a848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI ready\n",
      "Enable tracing at text_blob\n",
      "a js object contains 3 properties:\n",
      "    \"label\": str // always return 'ðŸ˜Š' \n",
      "    \"score\": int // an emotional score from 1 to 100 for the Happyness based the given user text\n",
      "    \"reason\": str// a reason for the score\n",
      "a js object contains 3 properties:\n",
      "    \"label\": str // always return 'ðŸ˜”' \n",
      "    \"score\": int // an emotional score from 1 to 100 for the Sadness based the given user text\n",
      "    \"reason\": str// a reason for the score\n",
      "a js object contains 3 properties:\n",
      "    \"label\": str // always return 'ðŸ˜ ' \n",
      "    \"score\": int // an emotional score from 1 to 100 for the Angryness based the given user text\n",
      "    \"reason\": str// a reason for the score\n",
      "a js object contains 3 properties:\n",
      "    \"label\": str // always return 'ðŸ˜²' \n",
      "    \"score\": int // an emotional score from 1 to 100 for the Surpriseness based the given user text\n",
      "    \"reason\": str// a reason for the score\n",
      "a js object contains 3 properties:\n",
      "    \"label\": str // always return 'ðŸ˜¨' \n",
      "    \"score\": int // an emotional score from 1 to 100 for the Fearness based the given user text\n",
      "    \"reason\": str// a reason for the score\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(\"../src\")\n",
    "from setup import get_openai_model, enable_tracing\n",
    "\n",
    "MODEL = get_openai_model()\n",
    "enable_tracing(\"text_blob\")\n",
    "\n",
    "\n",
    "\n",
    "def parse_nested_json(text):\n",
    "    a = text.strip()\n",
    "    json_data = a.strip().replace('```json', '').strip()\n",
    "    json_data = json_data.strip().replace('```', '').strip()\n",
    "    data = json.loads(json_data)\n",
    "    return data    \n",
    "\n",
    "response_schemas = []\n",
    "emos = ['Happy ðŸ˜Š','Sad ðŸ˜”','Angry ðŸ˜ ','Surprise ðŸ˜²','Fear ðŸ˜¨']\n",
    "# emos = ['Happy Happy','Sad Sad','Angry Angry','Surprise Surprise','Fear Fear']\n",
    "\n",
    "for emo in emos:\n",
    "    emos = emo.split(\" \")\n",
    "    # des = f\"\"\"a js array contains 3 elements in this order:\n",
    "    # 1. always return '{emos[1]}' \n",
    "    # 2. a emotional score from 1 to 100 for the {emos[0]} based the given user text\n",
    "    # 3. a reason for the score\"\"\"\n",
    "    des = f\"\"\"a js object contains 3 properties:\n",
    "    \"label\": str // always return '{emos[1]}' \n",
    "    \"score\": int // an emotional score from 1 to 100 for the {emos[0]}ness based the given user text\n",
    "    \"reason\": str// a reason for the score\"\"\"\n",
    "    print(des)\n",
    "    schema = ResponseSchema(name=emos[0], description=des)\n",
    "    response_schemas.append(schema)\n",
    "# define the output\n",
    "\n",
    "output_icon_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# prompt template\n",
    "template = \"\"\"You are good at detecting human emotion. All emotions you know are Negative, Positive and Neutral.\n",
    "Given an user text, your job is to answer as best as possible.\n",
    "{format_instructions}\n",
    "User text: {text}\"\"\"\n",
    "\n",
    "format_instructions = output_icon_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"],\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "# Build chain\n",
    "sentiment_icon_chain = LLMChain(llm=MODEL, prompt=prompt, output_key='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b45b5fa-484b-4560-bddc-c4d2c0199dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"I'm feeling lonely and I need a hug so bad! Hu hu!\",\n",
       " 'result': '\\n\\n```json\\n{\\n\\t\"Happy\": {\\n    \"label\": \"ðŸ˜Š\",\\n    \"score\": 10,\\n    \"reason\": \"The user expresses a need for companionship and comfort.\"\\n\\t},\\n\\t\"Sad\": {\\n    \"label\": \"ðŸ˜”\",\\n    \"score\": 90,\\n    \"reason\": \"The user expresses feelings of loneliness and sadness.\"\\n\\t},\\n\\t\"Angry\": {\\n    \"label\": \"ðŸ˜ \",\\n    \"score\": 0,\\n    \"reason\": \"No indication of anger in the user text.\"\\n\\t},\\n\\t\"Surprise\": {\\n    \"label\": \"ðŸ˜²\",\\n    \"score\": 0,\\n    \"reason\": \"No indication of surprise in the user text.\"\\n\\t},\\n\\t\"Fear\": {\\n    \"label\": \"ðŸ˜¨\",\\n    \"score\": 0,\\n    \"reason\": \"No indication of fear in the user text.\"\\n\\t}\\n}\\n```'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = sentiment_icon_chain({\"text\": \"I'm feeling lonely and I need a hug so bad! Hu hu!\"})\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9beab46b-b15b-48e8-887f-d8c16aa8f325",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17239/630974026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_nested_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Happy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'result'"
     ]
    }
   ],
   "source": [
    "ans = parse_nested_json(ans['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31751607-186a-4b57-94c5-5ad9458814a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Happy': {'label': 'ðŸ˜Š',\n",
       "  'score': 10,\n",
       "  'reason': 'The user expresses a need for companionship and comfort.'},\n",
       " 'Sad': {'label': 'ðŸ˜”',\n",
       "  'score': 90,\n",
       "  'reason': 'The user expresses feelings of loneliness and sadness.'},\n",
       " 'Angry': {'label': 'ðŸ˜ ',\n",
       "  'score': 0,\n",
       "  'reason': 'No indication of anger in the user text.'},\n",
       " 'Surprise': {'label': 'ðŸ˜²',\n",
       "  'score': 0,\n",
       "  'reason': 'No indication of surprise in the user text.'},\n",
       " 'Fear': {'label': 'ðŸ˜¨',\n",
       "  'score': 0,\n",
       "  'reason': 'No indication of fear in the user text.'}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
