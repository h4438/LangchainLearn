{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d2b5d1-c1a2-48e2-97b3-2506999d649a",
   "metadata": {},
   "source": [
    "# Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b47c07-ab5e-4697-a835-f40e589a6dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac13793f-d4f8-4543-abfc-5c49f5ae9516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "userText = \"Shut up! You are an idiot\"\n",
    "tb = TextBlob(userText)\n",
    "subjectivity = tb.subjectivity\n",
    "polarity = round(tb.polarity, 2)\n",
    "print(polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1113c5-ab88-4371-9ce7-77fd6a8e3d43",
   "metadata": {},
   "source": [
    "# 1 try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d86d7234-3a13-49b5-8140-ac909398d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI ready\n",
      "Enable tracing at text_blob\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from setup import get_openai_model, enable_tracing\n",
    "\n",
    "MODEL = get_openai_model()\n",
    "enable_tracing(\"text_blob\")\n",
    "\n",
    "\n",
    "# define the output\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"sentiment\", description=\"a sentiment label based on the user text. It should be either Negative, Positive or Neutral\"),\n",
    "    ResponseSchema(name=\"reason\", description=\"\"\"\n",
    "    If the sentiment is Negative then return the reason why the user shouldn't have said that.\n",
    "    If the sentiment is Positive then return a compliment.\n",
    "    For Neutral then return a instruct for a better message. \n",
    "    \"\"\"),\n",
    "    ResponseSchema(name=\"reply\", description=\"the best and friendliest replacement to the given user text\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# prompt template\n",
    "template = \"\"\"You are good at detecting human emotion. All emotions you know are Negative, Positive and Neutral.\n",
    "Given a human text, subjectivity and polarity, your job is to answer as best as possible.\n",
    "Know that subjectivity is a measure of how much of a text is based on personal opinions or beliefs, rather than on facts. \n",
    "It is a float value between 0 and 1, where 0 represents an objective text and 1 represents a highly subjective text.\n",
    "Also know that polarity is a indicator for the sentiment of the given user text, negative value means Negative, positive value means Positive and 0 means Neutral.\n",
    "{format_instructions}\n",
    "User text: {text}\n",
    "Subjectivity: {subjectivity}\n",
    "Polarity: {polarity}\"\"\"\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\",\"subjectivity\",\"polarity\"],\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "# Build chain\n",
    "sentiment_chain = LLMChain(llm=MODEL, prompt=prompt, output_key='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efad7591-eb0f-4867-b487-55e32050ccc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Have you heard about the new school',\n",
       " 'polarity': 0.14,\n",
       " 'subjectivity': 0.45454545454545453,\n",
       " 'result': '285714285714285\\n\\n```json\\n{\\n\\t\"sentiment\": \"Neutral\",\\n\\t\"reason\": \"This statement is too vague and does not provide enough information.\",\\n\\t\"reply\": \"What do you know about the new school?\"\\n}\\n```'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "userText = \"Have you heard about the new school\"\n",
    "tb = TextBlob(userText)\n",
    "subjectivity = tb.subjectivity\n",
    "polarity = round(tb.polarity, 2)\n",
    "\n",
    "ans = sentiment_chain({\"text\": userText, \"polarity\": polarity, \"subjectivity\": subjectivity})\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2a14f-f3a7-4dcb-8607-c9de776a99cf",
   "metadata": {},
   "source": [
    "# 2 try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a017734a-42bc-4150-bb55-c2152fa9a848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI ready\n",
      "Enable tracing at text_blob\n",
      "a js object contains two properties:\n",
      "    label: str // always return 'ðŸ˜Š' \n",
      "    score: int // a emotional score from 1 to 100 based the given user text\n",
      "    reason: str // a reason for the score\n",
      "a js object contains two properties:\n",
      "    label: str // always return 'ðŸ˜”' \n",
      "    score: int // a emotional score from 1 to 100 based the given user text\n",
      "    reason: str // a reason for the score\n",
      "a js object contains two properties:\n",
      "    label: str // always return 'ðŸ˜ ' \n",
      "    score: int // a emotional score from 1 to 100 based the given user text\n",
      "    reason: str // a reason for the score\n",
      "a js object contains two properties:\n",
      "    label: str // always return 'ðŸ˜²' \n",
      "    score: int // a emotional score from 1 to 100 based the given user text\n",
      "    reason: str // a reason for the score\n",
      "a js object contains two properties:\n",
      "    label: str // always return 'ðŸ˜¨' \n",
      "    score: int // a emotional score from 1 to 100 based the given user text\n",
      "    reason: str // a reason for the score\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from setup import get_openai_model, enable_tracing\n",
    "\n",
    "MODEL = get_openai_model()\n",
    "enable_tracing(\"text_blob\")\n",
    "\n",
    "emotions = ['Happy ðŸ˜Š','Sad ðŸ˜”','Angry ðŸ˜ ','Surprise ðŸ˜²','Fear ðŸ˜¨']\n",
    "\n",
    "response_schemas = []\n",
    "for emo in emotions:\n",
    "    emos = emo.split(\" \")\n",
    "    des = f\"\"\"a js object contains two properties:\n",
    "    label: str // always return '{emos[1]}' \n",
    "    score: int // a emotional score from 1 to 100 based the given user text\n",
    "    reason: str // a reason for the score\"\"\"\n",
    "    print(des)\n",
    "    schema = ResponseSchema(name=emos[0], description=des)\n",
    "    response_schemas.append(schema)\n",
    "# define the output\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# prompt template\n",
    "template = \"\"\"You are good at detecting human emotion. All emotions you know are Negative, Positive and Neutral.\n",
    "Given an user text, your job is to answer as best as possible.\n",
    "{format_instructions}\n",
    "User text: {text}\"\"\"\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"],\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "# Build chain\n",
    "sentiment_chain = LLMChain(llm=MODEL, prompt=prompt, output_key='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b45b5fa-484b-4560-bddc-c4d2c0199dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"I'm feeling lonely and I need a hug so bad! Hu hu!\",\n",
       " 'result': '\\n\\n```json\\n{\\n\\t\"Happy\": {\\n        label: \"ðŸ˜Š\",\\n        score: 10,\\n        reason: \"The user expresses a need for companionship and comfort.\"\\n    },\\n\\t\"Sad\": {\\n        label: \"ðŸ˜”\",\\n        score: 90,\\n        reason: \"The user expresses feelings of loneliness and sadness.\"\\n    },\\n\\t\"Angry\": {\\n        label: \"ðŸ˜ \",\\n        score: 0,\\n        reason: \"No indication of anger in the user text.\"\\n    },\\n\\t\"Surprise\": {\\n        label: \"ðŸ˜²\",\\n        score: 0,\\n        reason: \"No indication of surprise in the user text.\"\\n    },\\n\\t\"Fear\": {\\n        label: \"ðŸ˜¨\",\\n        score: 0,\\n        reason: \"No indication of fear in the user text.\"\\n    }\\n}\\n```'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = sentiment_chain({\"text\": \"I'm feeling lonely and I need a hug so bad! Hu hu!\"})\n",
    "ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
